 - создал кластер в minikube, для большего интереса использовал флаги (--nodes=2) --vm-driver=virtualbox, по умолчанию почему-то docker и tollbox там не пашет.
 - скопировал /web-pod.yml, добавил туда readinessProbe, запустил web
 - проанализировал вывод describe
 - добавил livenessProbe, удалил web, запустил с новой конфигурацией
 - на вскидку не ответил на вопрос для самопроверки, пошел в контейнер web, запустил там команду из вопроса
в ответ получил что команды ps в контейнере нет. Это, конечно, проблема, но, думаю, вопрос был не про это. Предположу что в данном случае живость контейнера определяется доступностью порта потому что то что nginx запустился еще не гарантирует что все сетевые заморочки пода сделали свои дела, а значит говорить что pod is ready - рано. а вот доступность порта уже однозначно утверждает что можно высовывать подик. sh проверки наверно более актуальны для фоновых задач, кога действительно можно утверждать что если процесс есть, то под жив. Ну и наверно тут намекается на то что liveness проба запускается в сетевом пространстве имен пода и команда ps, если она запустится, покажет процессы всех контейнеров пода.
 - сделал Deployment, контейнеры web не становились ready - по всей видимости Init контейнеру не хватало прав на изменение содержимого volumeMounts. нашел анализируя логи и конфигурации что есть флаг volumeMounts -  readOnly: true. Ради эксперимента поставил false - взлетели.
 - Сделал ClusteIP, нашел его цепочки в iptables nat
 - Включил IPVS mode, почитал доку чем отличается от голого IPTABLES. Это часть ядра линукс, может обеспечивать более тонкую балансировку нагрузки черз random probability, лучше подходит для больших кластеров. IPVS также использует IPTABLES (ipset) для транспорта и фильтрации.
 - Зачистил правил iptables - получилось О_о
 - установил ipvsadm, проверил ping ClusterIP 
 - создал LoadBalancer, проверил конфигурации. Добавил маршрут до виртуалки миникуба в хостовую ОС и открыл страничку лого Express42
 - создал ingress-nginx, добавил к нему сервис лод балансера представленным манифестом - получил 404 от nginx по своему адресу балансера. 
 - создал странный сервис ClusterIP без ClusterIP (ресурс, доступный по имени и хранящий информацию об endpoints вместо iptables)  
 - создал по приложенному yaml ingress-прокси который сказал ингрессу (ingress-nginx) что по маршруту /web нужно стучаться к сервису web-svc за эндпоинтами, он знает.  Применил, открыл на адресе своего балансера адрес /web. Балансировка между подами уже не последовательная при обновлении страницы. mission complete.
